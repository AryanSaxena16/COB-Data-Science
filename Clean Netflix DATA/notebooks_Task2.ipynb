{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Step 1: Import necessary libraries\nimport pandas as pd\nimport numpy as np",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 2: Load the dataset\ndf = pd.read_csv('dataset-netflix.csv')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 3: Check for missing values in all columns\nmissing_values = data.isnull().sum()\nprint(\"Missing Values:\")\nprint(missing_values)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 4: Handle missing values\n# For 'director' column, replace missing values with 'Not Given'\ndata['director'].fillna('Not Given', inplace=True)\n\n# For 'country' and 'listed_in' columns, replace missing values with 'NULL'\ndata['country'].fillna('NULL', inplace=True)\ndata['listed_in'].fillna('NULL', inplace=True)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 5: Check and standardize data formats\ndata['date_added'] = pd.to_datetime(data['date_added'], errors='coerce').dt.strftime('%d/%m/%Y')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Step 6:# Checking and standardizing other formats\ndata['release_year'] = data['release_year'].astype(str)  # Convert release_year to string format\n\n# Extract numeric part of duration and convert to minutes\ndata['duration'] = data['duration'].str.extract('(\\d+)').fillna(0).astype(int)\ndata['duration'] = data['duration'].apply(lambda x: x*10 if 'Season' in str(x) else x)  # Assuming 10 episodes per season",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 7: Outlier check for 'release_year'\n# Since release year is a numeric value, we performed an outlier check using the IQR method.\nQ1 = df['release_year'].quantile(0.25)\nQ3 = df['release_year'].quantile(0.75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\noutliers_release_year = df[(df['release_year'] < lower_bound) | (df['release_year'] > upper_bound)]\n\n# Display the outliers\nprint(outliers_release_year)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 8: Outlier check for 'duration'\n# Duration includes both movies (in minutes) and TV shows (in seasons). We performed an outlier check separately for each.\n# For movies, we considered an IQR of around 30-60 minutes.\n# For TV shows, we considered an IQR of around 2-5 seasons.\n\n# First, handle movies\nmovies_duration = df[df['duration'].str.contains('min', na=False)]\nmovies_duration['duration'] = movies_duration['duration'].str.replace(' min', '').astype(int)\n\nQ1_movies = movies_duration['duration'].quantile(0.25)\nQ3_movies = movies_duration['duration'].quantile(0.75)\nIQR_movies = Q3_movies - Q1_movies\nlower_bound_movies = Q1_movies - 1.5 * IQR_movies\nupper_bound_movies = Q3_movies + 1.5 * IQR_movies\noutliers_movies_duration = movies_duration[(movies_duration['duration'] < lower_bound_movies) | (movies_duration['duration'] > upper_bound_movies)]\n\n# Display the outliers for movies\nprint(outliers_movies_duration)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 9: Handle outliers for movies' duration\n# We decided to cap the outliers to the upper bound value.\nmovies_duration['duration'] = np.where(movies_duration['duration'] > upper_bound_movies, upper_bound_movies, movies_duration['duration'])",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Step 10: Outlier check for 'TV shows'\nQ1_tv_shows = tv_shows_duration['duration'].quantile(0.25)\nQ3_tv_shows = tv_shows_duration['duration'].quantile(0.75)\nIQR_tv_shows = Q3_tv_shows - Q1_tv_shows\nlower_bound_tv_shows = Q1_tv_shows - 1.5 * IQR_tv_shows\nupper_bound_tv_shows = Q3_tv_shows + 1.5 * IQR_tv_shows\noutliers_tv_shows_duration = tv_shows_duration[(tv_shows_duration['duration'] < lower_bound_tv_shows) | (tv_shows_duration['duration'] > upper_bound_tv_shows)]\n\n# Display the outliers for TV shows\nprint(outliers_tv_shows_duration)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 11: Handle outliers for 'TV shows' seasons\n# We decided to cap the outliers to the upper bound value.\ntv_shows_duration['duration'] = np.where(tv_shows_duration['duration'] > upper_bound_tv_shows, upper_bound_tv_shows, tv_shows_duration['duration'])\n\n# Combine the cleaned movie and TV show dataframes\ncleaned_duration_df = pd.concat([movies_duration, tv_shows_duration])",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 12: Outlier check for date_added\n# (You can use statistical methods like IQR, or domain-specific knowledge)\n# For date_added, we can calculate IQR and remove entries outside the range\n\nQ1 = data['date_added'].quantile(0.25)\nQ3 = data['date_added'].quantile(0.75)\nIQR = Q3 - Q1\n\n# Define upper and lower bounds\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Filter out outliers\ndata = data[~((data['date_added'] < lower_bound) | (data['date_added'] > upper_bound))]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Step 13: Save the cleaned dataset to a new CSV file\ndata.to_csv('cleaned_dataset.csv', index=False)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}